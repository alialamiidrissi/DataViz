{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from googletrans import Translator\n",
    "from IPython.display import display, Image\n",
    "from functools import reduce\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_dir ='isa-data/xlsx'\n",
    "list_df_final = []\n",
    "i = -1\n",
    "# Dictionary used to associate a dummy sciper to students with missing Sciper number\n",
    "name_sciper= {}\n",
    "\n",
    "# Dictionary used to normalize sections names\n",
    "codes = {'AR':'Architecture','CGC':'Chemical Engineering and Biotechnology',\n",
    "         'GC':'Civil Engineering','EL':'Electrical and Electronics Engineering',\n",
    "         'GM':'Mechanical Engineering','IN':'Computer Science','IF':'Financial engineering',\n",
    "         'MA':'Mathematics','MT':'Microengineering',\n",
    "         'MX':'Materials Science and Engineering',\n",
    "         'SC': 'Communication Systems','SIE':'Environmental Sciences and Engineering',\n",
    "         'SV':'Life Sciences and Technologies','MTE':'Management','PH':'Physics'}\n",
    "\n",
    "def getSciper(key):\n",
    "    ''' Function that assign a dummy sciper to a student without sciper number in our database'''\n",
    "    global i,name_sciper\n",
    "    try:\n",
    "        return name_sciper[key]\n",
    "    except KeyError:\n",
    "        name_sciper[key] = i\n",
    "        ret = i\n",
    "        i-=1\n",
    "        return ret\n",
    "def clean_type(type_):\n",
    "    ''' Function used to parse the headers and clean some fields'''\n",
    "    global i\n",
    "    \n",
    "    # Check if header exists\n",
    "    if(type_['Level'] is None):\n",
    "        return type_\n",
    "    # Split header \n",
    "    temp= type_['Level'].split(',')\n",
    "    \n",
    "    # Collect the section name from the header\n",
    "    type_['section'] = temp[0]\n",
    "    level = temp[2] if (temp[0] != 'Management') else temp[3]\n",
    "    type_['Level']= re.sub(r\"\\xa0(.)*\", r\"\",level).strip()\n",
    "    \n",
    "    '''Clean and normalize the nationality field in order to keep only one nationality in the case where a student has\n",
    "    multiples ones '''\n",
    "    \n",
    "    if(type(type_['Nationalité']) == str):\n",
    "        if(('Suisse' in type_['Nationalité']) or ('Swiss' in  type_['Nationalité'])):\n",
    "            type_['Nationalité']='Swiss'\n",
    "        else:\n",
    "            temp = re.split(r\"(,+|;+)\", type_['Nationalité'])\n",
    "            if(len(temp) > 1):\n",
    "                type_['Nationalité']=temp[0].strip()\n",
    "                \n",
    "    # Determine if the current entry contains infos about an exchange student \n",
    "    exchange = 'Exchange' in type_['section'] or 'Echange' in type_['section']\n",
    "    type_['Exchange_student'] = exchange\n",
    "    if(exchange):\n",
    "        type_['section']=codes[re.sub(r\"Exchange|Echange\", r\"\",type_['section']).strip()]\n",
    "        \n",
    "    type_['section']= re.sub(r\"-(.)*\", r\"\",type_['section']).strip()\n",
    "    \n",
    "    # Get dummy sciper if the latter is not defined\n",
    "    if(type(type_['No Sciper']) != int ):\n",
    "        type_['No Sciper'] = getSciper(type_['Nom Prénom'])\n",
    "        \n",
    "    # Determine the type of student\n",
    "    if type_['Exchange_student']:\n",
    "        type_['Type']='Exchange'\n",
    "    elif type_['section'] == 'CMS':\n",
    "        type_['Type']='CMS'\n",
    "    elif type_['section'] == 'Passerelle HES':\n",
    "        type_['Type']= 'Passerelle HES'\n",
    "    elif 'Master' in type_['Level']:\n",
    "        type_['Type']= 'Master'\n",
    "    elif ('Bachelor' in type_['Level']) or ('training course' in type_['Level']):\n",
    "        type_['Type']= 'Bachelor'\n",
    "    \n",
    "    return type_\n",
    "\n",
    "def process_df(df,year):\n",
    "    ''' Function that processes individually every excel file'''\n",
    "    \n",
    "    # Get headers\n",
    "    df.columns = df.loc[1,:].tolist()\n",
    "    df = df[df['Civilité']!='Civilité'].reset_index(drop=True)\n",
    "    df['Level'] = None\n",
    "    types = df[ (df['Civilité']!='Miss') & (df['Civilité']!='Mister')]['Civilité']\n",
    "    types_index = types.index.tolist()\n",
    "    types = types.tolist()\n",
    "    \n",
    "    # Associate every entry to its corresponding header\n",
    "    for i in range(len(types_index)):\n",
    "        index_2 = 0\n",
    "        if(i != len(types_index)-1):\n",
    "            index_2= types_index[i+1]\n",
    "        else:\n",
    "            index_2 = len(df)-1\n",
    "\n",
    "        df.loc[types_index[i]:index_2,'Level']= types[i]\n",
    "\n",
    "    # Drop headers\n",
    "    df = df.loc[(df['Civilité']=='Miss')|(df['Civilité']=='Mister')].reset_index(drop = True)\n",
    "    df['Year']= year\n",
    "    df['section'] = None\n",
    "    df['Exchange_student']= None\n",
    "    df['Type']= None\n",
    "    \n",
    "    # Call clean_type function which will parse the header to extract the Year,section,Type\n",
    "    #(Bachelor,Master,Exchange, CMS ,passerelle HES ) of every entry\n",
    "    df = df.apply(clean_type,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading and preprocessing all excel files\n",
    "for file in os.listdir(path_to_dir):\n",
    "    df= pd.read_excel(os.path.join(path_to_dir,file))\n",
    "    year_df = process_df(df,file.split('.')[0])\n",
    "    list_df_final.append(year_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69262"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def unique_entries(df):\n",
    "    ''' Function used to list a student only once in a certain year dataframe'''\n",
    "    if((df['Nom Prénom'] != df['Nom Prénom'].iloc[0]).any()):\n",
    "        display(df)\n",
    "    ret = df[~(df['Type'].isnull())]\n",
    "    if(len(ret)>0):\n",
    "        ret = ret.head(1)\n",
    "    else:\n",
    "        ret= df.head(1)\n",
    "    return ret\n",
    "\n",
    "# group the entries in every excel file by sciper number and use the unique_entries function to reduce them\n",
    "list_df_final = list(map(lambda x : (x.groupby(by='No Sciper')).apply(unique_entries),list_df_final))\n",
    "reduce(lambda x,y:x+y ,list(map(lambda x:len(x),list_df_final)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_final = list(map(lambda x : x.reset_index(drop = True),list_df_final))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate all loaded dataframes into a unique one\n",
    "final_df = pd.concat(list_df_final,ignore_index=True)\n",
    "\n",
    "# Normalizing sections names and nationalities + other fields \n",
    "final_df.loc[final_df.section == 'Management of Technology','section'] = 'Management'\n",
    "final_df.loc[final_df.section == 'Systèmes de communication','section'] = 'Communication Systems'\n",
    "final_df.replace(u'\\xa0',u' ', regex=True, inplace=True)\n",
    "final_df['Nationalité'].replace(u'suisse',u'Swiss', regex=True, inplace=True)\n",
    "final_df['Nationalité'].replace(u';',u',', regex=True, inplace=True)\n",
    "\n",
    "# try to find sciper numbers for entries which does not have one using informations from the others dataframes.\n",
    "# If a valid sciper number is not found we associate the same dummy sciper for entries with the same name attribute\n",
    "bad_entries = final_df[final_df['No Sciper']< 0]\n",
    "bad_entries_names = bad_entries['Nom Prénom'].unique()\n",
    "for name in bad_entries_names:\n",
    "    sciper = final_df[(final_df['No Sciper']>0) & (final_df['Nom Prénom'] == name)]\n",
    "    if(len(sciper)>0):\n",
    "        final_df.loc[(final_df['No Sciper']<0) & (final_df['Nom Prénom'] == name),'No Sciper']= (sciper['No Sciper'].reset_index(drop=True))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary used to map every nationality with its country code , this step is necessary to display nationality infos in Leaflet maps\n",
    "# At this step the dictionary only associates to every nationality in our df it correspendant name in english\n",
    "mapping_code_nat = dict(list(map(lambda x: (x,translator.translate(x,dest = 'en').text.title()) if type(x) == str else (x,x),final_df['Nationalité'].unique().tolist())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handle manually some nationalities names which were badly translated\n",
    "\n",
    "mapping_code_nat['kosovar'] = 'Kosovar'\n",
    "mapping_code_nat['centrafricaine']= 'Central African'\n",
    "mapping_code_nat['Philippine']= 'Filipino'\n",
    "mapping_code_nat['néo-zélandaise'] = 'New Zealander'\n",
    "mapping_code_nat['liechtensteinoise']='Liechtensteiner'\n",
    "mapping_code_nat['Qatar']= 'Qatari'\n",
    "mapping_code_nat['lettonne']= 'Latvian'\n",
    "mapping_code_nat['Bangladesh']= 'Bangladeshi'\n",
    "\n",
    "# uniformize nationalities\n",
    "def f(row):\n",
    "    global mapping_code_nat,csv_code\n",
    "    if(row['Nationalité'] is not None) and (type(row['Nationalité'])== str):\n",
    "        row['Nationalité'] = mapping_code_nat[row['Nationalité']]\n",
    "    return row\n",
    "final_df_copy= final_df.apply(f,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load a csv files found on internet which associates nationalities to countries codes\n",
    "csv_codes = pd.read_csv('isa-data/Countries-List.csv',encoding='utf-16')\n",
    "csv_codes = csv_codes.set_index('Demonym_1').to_dict('index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our dictionary that maps countries code to citizenships\n",
    "nat_code = {v['ISO_Code']: k for k, v in csv_codes.items()}\n",
    "\n",
    "nat_code['YF'] = 'Serbian'\n",
    "nat_code['ZR'] = 'Congolese'\n",
    "nat_code['GN'] = 'Guinean'\n",
    "nat_code['NA'] = 'Namibian'\n",
    "nat_code['SD'] = 'Sudanese'\n",
    "nat_code['GZ'] = 'Israeli'\n",
    "nat_code['TP'] = 'East Timorian'\n",
    "nat_code['RY'] = 'Yemeni'\n",
    "\n",
    "js = json.dumps(nat_code)\n",
    "fp = open('code_nat.json', 'a')\n",
    "fp.write(js)\n",
    "fp.close()\n",
    "\n",
    "# Save our dictionary that maps citizenships to countries names\n",
    "nat_country ={}\n",
    "config = json.loads(open('isa-data/custom.geo.json').read())\n",
    "\n",
    "    \n",
    "for i in  config['features']:\n",
    "    code = None\n",
    "    if (i['properties']['wb_a2'] != '-99'):\n",
    "        code = i['properties']['wb_a2']\n",
    "    else:\n",
    "        code = i['properties']['postal']\n",
    "    if(code not in nat_code):\n",
    "        print(i['properties']['sovereignt'],code)\n",
    "    else:\n",
    "        nat_country[nat_code[code]] = i['properties']['sovereignt']\n",
    "    if(code == '-99'):\n",
    "        print(i)\n",
    "        \n",
    "\n",
    "\n",
    "js = json.dumps(nat_country)\n",
    "fp = open('nat_country.json', 'a')\n",
    "fp.write(js)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed dataframe and keep only columns that will be useful in our data visualization\n",
    "final_df_copy[['Civilité','Year','Type','section','Nationalité']].to_csv('cleaned_isa_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
